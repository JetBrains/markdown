# Knowtify Log Analytics (Client Application & Data Service)

This is a single .war file deployment of **Knowtify Log Analytics** by *Springblox*

## Step 1 - Install PostgreSQL
1. Install PostgreSQL v9.4 - production systems (see Developer Notes below for additional persistence options)
    1. Red Hat 7 family (version 7.x  Red Hat Enterprise Linux, CentOS, Fedora, Scientific Linux, Oracle Linux and others) Commands for the Red Hat 6 family, where different, are noted in square brackets [RH6: ~command~ ] see: http://www.unixmen.com/postgresql-9-4-released-install-centos-7/, and http://www.postgresql.org/download/linux/redhat/
        1. Install PostgreSQL 9.4 repo:`yum install http://yum.postgresql.org/9.4/redhat/rhel-7-x86_64/pgdg-redhat94-9.4-1.noarch.rpm`    [RH6:`yum install http://yum.postgresql.org/9.4/redhat/rhel-6-x86_64/pgdg-redhat94-9.4-1.noarch.rpm`]
        1. Install PostgreSQL: `yum install postgresql94-server postgresql94-contrib`
        1. Initialize the databases: `/usr/pgsql-9.4/bin/postgresql94-setup initdb` [RH6:`service postgresql-9.4 initdb`]
        1. Install the service: `systemctl enable postgresql-9.4`  [RH6:`chkconfig postgresql-9.4 on`]
        1. Start the service: `systemctl start postgresql-9.4`  [RH6:`service postgresql-9.4 start`]
        1. The PosgtreSQL config files are located in /var/lib/pgsql/9.4/data/

    1. Ubuntu see: https://help.ubuntu.com/community/PostgreSQL
        1. Install PostgreSQL: `apt-get install postgresql postgresql-contrib`
        1. Setup a password for the postgres user: `/password postgres`
        1. Start/Restart the PostgreSQL service: `/etc/init.d/postgresql start`  (or stop, restart...)
        1. The PosgtreSQL config files are located in /etc/postgresql/9.3/main

1. Configure PostgreSQL for client and remote access
    1. Edit postgresql.conf
        1. `listen_addresses = '*'`
    1. Edit pg_hba.conf - allow local and internal-network connections
        1. `host   all   all   127.0.0.1/32    md5`
        1. `host   all   all   172.16.0.0/12   md5`
        1. NOTE: Ubuntu running PostgreSQL 9.3 also required this entry be changed
            1. from: `local   all   postgres   peer`
            1. to: `local   all   postgres   md5`
    1. For remote access to the database (Red Hat 7 family)
        1. open the firewall: `firewall-cmd --zone=public --add-port=5432/tcp --permanent`
        1. reload the firewall config: `firewall-cmd --reload`
        1. add connectivity to your network address, for example if your network address is 192.168.91.1, add `host all all 192.168.0.0/12 md5` and restart Postgres
    1. For remote access to the database (Red Hat 6 family)
        1. edit iptables: `-A INPUT -m state --state NEW -m tcp -p tcp --dport 5432 -j ACCEPT`
        1. add the following: `service iptables restart`
        1. add connectivity to your network address, for example if your network address is 192.168.91.1, add `host all all 192.168.0.0/12 md5` and restart Postgres

1. Copy the contents of the /postgreSql directory
1. Update the appropriate installDb script (.sh or .cmd) with your postgres user password and the PostgreSQL installation location (C:\Program Files\PostgreSQL\9.4 is the default location for 64bit PostgreSQL on windows).
1. As the postgres user CD to the directory with the scripts and run the script (Linux: `sudo -u postgres ./installDb.sh`).
1. Verify you can connect to the knowtify database:
    1. Windows: use PgAdminIII, connect to the db, verify you have a knowtify database, with a kla schema containing 3 tables, and data in the SolrSchema table.
    1. Red Hat 6 & 7 family: run pgsql and verify you can connect: `/usr/pgsql-9.4/bin/psql -h 127.0.0.1 -U klauser knowtify` (password is klapassword)
    1. Ubuntu: run pgsql and verify you can connect: `psql -h 127.0.0.1 -d knowtify -U klauser`  (password is klapassword)
    1. Run a command in psql to list out the Knowtify tables: `\dt kla.*`
    1. Exit pgsql: `\q`


## Step 2 - Install Java
### Java - install and configure Java v1.8 (Red Hat 7 family)
1. `mkdir /opt/java`
1. `cd /opt/java`
1. `wget --no-check-certificate --no-cookies --header "Cookie: oraclelicense=accept-securebackup-cookie"  http://download.oracle.com/otn-pub/java/jdk/8u60-b27/jdk-8u60-linux-x64.tar.gz -O jdk-8u60-linux-x64.tar.gz`
1. `tar xvzf jdk-8u60-linux-x64.tar.gz`
1. `chown -R root.root jdk1.8.0_60/`
1. `alternatives --install /usr/bin/java java /opt/java/jdk1.8.0_60/bin/java 2`
1. `alternatives --config java`
1. edit java.sh `vi /etc/profile.d/java.sh` and add: `export JAVA_HOME=/opt/java/jdk1.8.0_60`
1. verify you have the right version of java installed and running: `java --version`  should display: java version "1.8.0_60"
1. delete your gzip file `rm *.gz`


## Step 3 - Install Tomcat
### Tomcat - install and configure Tomcat 7 (Red Hat 7 family)
1. Install Tomcat 7 (RH7 only: yum option, see: https://www.digitalocean.com/community/tutorials/how-to-install-apache-tomcat-7-on-centos-7-via-yum)
    1. `yum install tomcat`
    1. The important Tomcat files are located in /usr/share/tomcat
    1. The deployment directory (for .war files) is /usr/share/tomcat/webapps
    1. Tomcat is configured via settings in tomcat.conf  (add the KNOWTIFY_CONFIG and CATALINA_BASE env variables here)
    1. Enable the service for restart: `systemctl enable tomcat`
    1. Start the service: `systemctl start tomcat`

1. Install Tomcat 7 (manual, Red Hat 6 family)
    1. `cd /opt`
    1. `wget http://www.us.apache.org/dist/tomcat/tomcat-7/v7.0.64/bin/apache-tomcat-7.0.64.tar.gz`
    1. `tar xvzf apache-tomcat-7.0.64.tar.gz`
    1. delete your gzip file `rm *.gz`
    1. Remove the tomcat manager apps: `cd /opt/apache-tomcat-7.0.64/webapps; rm -r *`
    1. Knowtify settings can be added via setenv.sh

#### Step 3a Securing Tomcat on Linux (manual installs, Red Hat 6 family)
1. Create a tomcat group: `/usr/sbin/groupadd tomcat`
1. Create a tomcat user: `/usr/sbin/useradd -s /sbin/nologin -Md /opt/apache-tomcat-7.0.64 tomcat -g tomcat`
1. Set tomcat password: `passwd tomcat`  (I used: QxuEp8 for the password on the DSE box, on Centos, John used Cxr@ff2)
1. Change ownership of the tomcat install directory: `chown -R tomcat.tomcat /opt/apache-tomcat-7.0.64`
1. Change permissions of the tomcat install directory: `chmod 775 /opt/apache-tomcat-7.0.64`
1. Change permissions of the tomcat bin directory: `cd /opt/apache-tomcat-7.0.64/bin; chmod 755 *.sh`
1. Other Tomcat security related considerations:
    1. Change the default port of tomcat from 8080 to 80 (so no port number required in URL, see below)
        1. Since tomcat is not running as root this requires an iptables or other network change
        1. The port tomcat runs on is set in CATALINA_HOME/conf/server.xml
    1. Install tomcat to start at boot time  (specifics are Linux version dependant)
    1. Install SSL for tomcat (also will require iptables/network changes if using standard https port of 443, see below)
    1. Be sure to update the firewall to close off unneeded ports

#### Step 3b (optional) Tomcat: install SSL with a Self-Signed Cert
1. Generate a self signed cert:

    root@ip-172-31-27-155:/opt/certs#
    `keytool -genkey -alias tomcat -keyalg RSA -keystore /opt/certs/tomcatSSLKeystore`

    Enter keystore password: **changeit**

    Re-enter new password: **changeit**

    What is your first and last name?  
    [Unknown]: **ISS Inc.**

    What is the name of your organizational unit?  
    [Unknown]:  **SpringBlox**

    What is the name of your organization?  
    [Unknown]:  **PSI**

    What is the name of your City or Locality?  
    [Unknown]:  **Colorado Springs**

    What is the name of your State or Province?  
    [Unknown]:  **CO**

    What is the two-letter country code for this unit?  
    [Unknown]:  **US**

    Is CN=ISS Inc., OU=SpringBlox, O=PSI, L="Colorado Springs", ST=CO, C=US correct?  
    [no]: **y**

    Enter key password for [tomcat]  
    (RETURN if same as keystore password): **return**

1. Update server.xml uncomment and edit the SSL Connector on 8443:  

    `<Connector port="8443" protocol="org.apache.coyote.http11.Http11Protocol"`  
    `    maxThreads="150" SSLEnabled="true" scheme="https" secure="true"`  
    `    clientAuth="false" sslProtocol="TLS"`  
    `    keystoreFile="/opt/certs/tomcatSSLKeystore"`
    `    keystorePass="changeit" />`  

1. Shutdown and restart Tomcat, you should now be able to connect on https://[hostname]:8443

#### Step 3c (optional) Tomcat: redirect access to standard ports (Red Hat 6 family)
1. By default tomcat is running with HTTP on port 8080 and HTTPS on port 8443 and the tomcat
server is running as the tomcat user (if configured as above).  BUT, the non-root users
cannot bind to ports less than 1024 so we cannot simply change the `<Connector>` ports in server.xml.
1. To get around this issue we need to redirect traffic from port 80 to port 8080 (and 443 to 8443 if HTTPS is in use).
This allows use of standard URL's without port numbers and requires the following iptables commands:
    1. For HTTP (80):

    `iptables -t nat -I PREROUTING -p tcp --dport 80 -j REDIRECT --to-ports 8080`
   
    `iptables -t nat -I OUTPUT -p tcp -o lo --dport 80 -j REDIRECT --to-ports 8080`

    1. For HTTPS (443):

    `iptables -t nat -I PREROUTING -p tcp --dport 443 -j REDIRECT --to-ports 8443`

    `iptables -t nat -I OUTPUT -p tcp -o lo --dport 443 -j REDIRECT --to-ports 8443`

    1. To save the settings so that they persist across reboots: `iptables-save > /etc/sysconfig/iptables`


## Step 4 Configure the KLA Web App
1. As part of installing KLA, you must configure your system via a local overrides file.  This requires editing a file on the local machine and setting an environment variable which points to that file. A sample file is located in the /resources directory (knowtifyConfig.properties)
1. KLA accesses the local overrides file via the Environment Variable: **KNOWTIFY_CONFIG** (i.e. `KNOWTIFY_CONFIG=/opt/knowtifyConfig.properties`)
1. The Solr instance type you connect to must be configured via the **solr_provider** and **solr_url** settings:
    3. For a single instance Solr server the local overrides file should contain:
        1. **solr_provider=Single**.
        2. **solr_url** property should be set to the full http address of Solr (i.e. `solr_url=http://172.22.60.178:8983/solr`).
    4. For a cloud instance of Solr the local overrides file should contain:
        1. **solr_provider=Cloud**.
        2. **solr_url** property should be a list of the Zookeeper nodes managing Solr Cloud (zkhosts setting with IP addresses and port: i.e. `solr_url=172.29.24.42:2181,172.29.24.46:2181/logstash_chroot`).
    5. For Load Balanced (DataStax) instances of Solr Cloud the local overrides file should contain:
        1. **solr_provider=Load Balanced**.
        2. **solr_url** property should be a list of the Solr hosts (i.e. `solr_url=http://52.7.123.220:8983/solr,http://52.5.137.196:8983/solr`).
5. The **solr_core** property should be set to specify the appropriate Solr Core or Collection name.
6. OPTIONAL: The client must be able to query for a schema from Solr in order to operate properly.  For Solr instances which do not correctly return results from /schema/fields query (DataStax) a local file copy of the schema can be specified via the **solr_schema_file** parameter (i.e. `solr_schema_file=c:/opts/schema.json`).
6. OPTIONAL: For Solr instances which require additional query parameters (DataStax), those parameters can be specified in the **solr_query_params** option (i.e. `solr_query_params=&df=message_text`).
7. Persistence can be implemented via PostgreSql, MySql, or H2 Db.  Persistence allows saving the users dashboard configurations, the data service configuration, and solr schemas.
    1. The **persistence_provider_context** property controls whether to use PostgreSql, MySql, or H2 Db the default option is H2. Use postgresContext.xml for Postgres, mysqlContext.xml for MySql, or h2Context.xml for H2 Db (i.e. `persistence_provider_context=postgresContext.xml`).
    1. The **persistence_provider_class** property should be set to com.issinc.knowtify.service.persistence.SpringDataService (i.e. `persistence_provider_class=com.issinc.knowtify.service.persistence.SpringDataService`).

    2. The PostgreSql database is assumed to be installed on localhost at port 5432.
    3. For PostgreSql the InstallDb.cmd file will create the database and all required components for persistence.

    2. The MySql database is assumed to be installed on localhost at port 3306.
    3. For MySql, you will need to manually create the Db user (klauser/klapassword), database (knowtify), and create the tables using the /mySql/schema/CreateTables.sql file.

    3. For H2 Db the database is created and populated on the first run of the application, no installation scripts are required.

    1. **BETAt** For Apache Jena persistence the **persistence_provider_location** property should be set to an *existing* location on the local file system that is readable and writable by the tomcat user (i.e. `persistence_provider_location=/opt/knowtifyData`).  **Note:** you *must* create this directory manually if it doesn't already exist.



## Step 5 Deploy the KLA Web App
1. Manual Tomcat installs: copy *setenv.sh* to /opt/apache-tomcat-7.0.64/bin (verify/edit the path locations )
1. Yum Tomcat installs: edit *tomcat.conf* and add `export KNOWTIFY_CONFIG=/opt/knowtifyConfig.properties`
1. Copy *knowtifyConfig.properties* to /opt (or to the directory specified in setenv.sh/tomcat.conf).
1. Edit the Configuration Parameters in *knowtifyConfig.properties* as needed for your Solr instance and persistence choice.
1. Copy knowtify.war to the Tomcat webapps directory
1. Start the Tomcat server (as tomcat):
    1. *ubuntu* `su - -s /bin/bash -c /opt/apache-tomcat-7.0.63/bin/startup.sh tomcat`
    2. *RH6 manual* `sudo -u tomcat /opt/apache-tomcat-7.0.64/bin/startup.sh`
    2. *RH7 yum* `sudo systemctl start tomcat`
1. To stop the Tomcat server:
    1. *ubuntu* `su - -s /bin/bash -c /opt/apache-tomcat-7.0.63/bin/shutdown.sh tomcat`
    2. *RH6 manual* `sudo -u tomcat /opt/apache-tomcat-7.0.64/bin/shutdown.sh`
    2. *RH7 yum* `sudo systemctl stop tomcat`
1. Verify tomcat is running: `ps -ef|grep tomcat`



## Step 6 Data Ingestion - Logstash
Logstash is used to provide log data to Knowtify Log Analytics.  It should be installed and configured on each machine that produces logs for KLA.  Each source log file requires a configuration file.  Multiple configuration files (i.e. multiple logs) may be processed by a single Logstash instance.

### -Install Logstash (Red Hat 6 & 7 family)
1. Install Java if not already available (Logstash requires Java 1.7 or better: Java 1.8 is strongly recommended.)
1. Install Logstash 1.5.4
    1. `cd /opt`
    1. Download TAR.GZ from Elastic: `wget https://download.elastic.co/logstash/logstash/logstash-1.5.4.tar.gz`
    1. `tar xvzf logstash-1.5.4.tar.gz`
1. install the solr\_http output plugin (info at https://www.elastic.co/guide/en/logstash/current/plugins-outputs-solr_http.html):
    1. `cd /opt/logstash-1.5.4`
    1. Install the plugin: `bin/plugin install logstash-output-solr_http`
1. Create a symlink for logstash `ln -s /opt/logstash-1.5.4 /opt/logstash`
1. Copy the logstash service script *logstash-initscript.sh* to */etc/init.d/logstash* `cp /opt/logstash-1.5.4/logstash-initscript.sh /etc/init.d/logstash`
1. Set the service script run levels `/sbin/chkconfig --levels 2345 logstash on`
1. Set the service script to be executable `chmod 755 /etc/init.d/logstash`
1. Create a directory for the Logstash config files `mkdir /opt/logstash-1.5.4/conf.d`
1. Copy the appropriate Logstash config files for the log types you wish to collect to /opt/logstash-1.5.4/conf.d.
1. The config files will need to be edited with the location of this system's log files and the Solr Location (edit the **path =>** and **solr_url** values).  For debugging use the **stdout** output line, comment this line out for production use.
1. To run logstash manually from the command line (for debug purposes): `/opt/logstash/bin/logstash agent -f /opt/logstash/conf.d/`
1. To start the logstash service: `/sbin/service logstash start`
1. The available service command options are: start, stop, status, restart
1. The Logstash log file is located in /var/log/logstash.log.

### -Install Logstash (Ubuntu 14.04)
1. Install Java if not already available (see above)
1. On Ubuntu 14.04, Logstash will not run due to a known bug (missing file):   `/usr/lib/x86_64-linux-gnu/libcrypt.so`
1. To fix the problem, run this command: `ln -s /lib/x86_64-linux-gnu/libcrypt.so.1 /usr/lib/x86_64-linux-gnu/libcrypt.so`
1. The issue is documented in this web exchange:`https://github.com/elastic/logstash/issues/3127`

### -Install Logstash (Windows)
1. Install Java if not already available
1. Install Logstash 1.5.4
    1. Download the Logstash 1.5.4 ZIP file from `https://www.elastic.co/downloads/logstash`
    1. Unzip the ZIP file to a location of your choice.  We'll refer to that location as *%LOGSTASH_HOME%*
1. On a clean Windows environment the JAVA\_HOME variable needs to be set.
    1. Right click my computer, select Properties
    1. Click Environment Variables
    1. Under System variables, click New
    1. Variable name: `JAVA_HOME`
    1. Variable value: *this will need to point to the system java installation folder. Something like C:\Progra~2\java\jre\*
    1. Click OK to save
    1. Test in a newly opened command prompt with `cd %JAVA_HOME%`  note, if this doesn't work, a restart may be required.
1. Install the Windows Event Log input plugin (info at https://www.elastic.co/guide/en/logstash/current/plugins-inputs-eventlog.html#plugins-inputs-eventlog-type):
    1. `cd %LOGSTASH_HOME%`
    1. install the plugin: `bin\plugin install logstash-input-eventlog`
1. Install the solr\_http output plugin (info at https://www.elastic.co/guide/en/logstash/current/plugins-outputs-solr\_http.html):
    1. `cd %LOGSTASH_HOME%`
    1. install the plugin: `bin\plugin install logstash-output-solr_http`
1. Copy the logstash-eventlog.conf to %LOGSTASH\_HOME%
    1. Supported files can be found in: `knowtify_kla/src/main/resources/Windows/`
1. Create a run.bat file in %LOGSTASH\_HOME%\bin. It should contain this command `logstash.bat agent -f %LOGSTASH_HOME%\logstash-eventlog.conf`
1. To install Logstash to run as a Windows Service:
    1. Download NSSM from http://nssm.cc/
    1. Unzip NSSM-??.zip to a temporary directory
    1. Copy the win32 or win64 version (as appropriate) of nssm.exe to %LOGSTASH\_HOME%\bin
    1. Open a command window and go to %LOGSTASH\_HOME%\bin.  Run `.\nssm install Logstash`
    1. On the Application Tab, edit the Path: setting to `%LOGSTASH_HOME%\bin\run.bat`
    1. On the Details tab set the Display name: and Service name: to `Logstash`.
    1. Press Install service.
    1. You should now be able to start Logstash from the Windows Services console.


## Step 7 Install Zookeeper Instances
Zookeeper is required for SolrCloud to maintain and synchronize the Solr server instances in the clustered configuration.  You must install ZooKeeper on an odd number of machines. The number of machines will determine if you install ZooKeeper in standalone mode (for one machine) or in replicated mode (for three or five machines).

1. Install and Configure Zookeeper, on all Zookeeper nodes (requires Java):
    1. Open ports 2181 and 2888 - 3888
        2. Red Hat 6 family
            3. Open port 2181: `iptables -A INPUT -p tcp --dport 2181 -j ACCEPT`
            3. Open ports 2888-3888: `iptables -A INPUT -p tcp --dport 2888:3888 -j ACCEPT`
            3. Save the iptables changes: `iptables-save > /etc/sysconfig/iptables`
            3. Check firewall status: `iptables -L`
        2. Red Hat 7 family
            3. Open port 2181: `firewall-cmd --zone=public --add-port=2181/tcp --permanent`
            3. Open port 2888-3888: `firewall-cmd --zone=public --add-port=2888:3888/tcp --permanent`
            3. Save the iptables changes: `firewall-cmd --reload`
            3. Check firewall status: `sudo iptables -L`
        2. Ubuntu
            3. Check firewall status: `sudo ufw status verbose`
            3. Open port 2181: `sudo ufw allow 2181/tcp`
            3. Open ports 2888-3888: `sudo ufw allow 2888:3888/tcp`
    1. Install Zookeeper
        1. `cd /opt`
        1. `wget http://apache-mirror.rbc.ru/pub/apache/zookeeper/zookeeper-3.4.6/zookeeper-3.4.6.tar.gz`
        1. `gunzip -c *.gz | tar xvf -`
    1. Configure your zookeeper cluster
        2. `cd zookeeper-3.4.6/conf`
        2. `cp zoo_sample.cfg zoo.cfg`
        2. Edit zoo.cfg:
            3. change the data dir: **dataDir=/var/zookeeper**
            3. add a line for each ZK host in your cluster:
                4. **server.1=zk1-host:2888:3888**
                4. **server.2=zk2-host:2888:3888**
                4. **server.3=zk3-host:2888:3888**
        2. Create a **myid** file in /var/zookeeper, add the server id to the file (i.e. for zoo1-host the file would just contain the character "1")
        2. rename zkServer.sh and copy in the version in /resources/CentOS
        2. create a symlink to run ZK as a service: `sudo ln -s /opt/zookeeper-3.4.5/bin/zkServer.sh /etc/init.d/zookeeper`
        2. configure the service to autostart: `chkconfig zookeeper on`
        2. start ZK: `sudo /sbin/service zookeeper start`
        2. verify ZK is running: `echo "ruok" | nc localhost 2181  ; echo ''`  you should receive an response of: imok


## Step 8  Install Solr Cloud Instances

### -Option 1, Production Script Installation (most Linux flavors, see: https://cwiki.apache.org/confluence/display/solr/Taking+Solr+to+Production )
1. Install Solr Cloud on Linux (requires Java, Zookeeper)
    1. `cd /opt`
    1. `wget http://apache.mirrors.pair.com/lucene/solr/5.3.1/solr-5.3.1.tgz`
    1. `tar xzf solr-5.0.0.tgz solr-5.0.0/bin/install_solr_service.sh --strip-components=2`
    1. `./install_solr_service.sh solr-5.0.0.tgz`
    1. By default this script will
        2. install solr with a symbolic link in /opt,
        2. create a solr user,
        2. create a service to run solr as the solr user on the default port (8983) with autostart,
        2. set Solr database storage to /var/solr,
        2. starts solr and displays the running status
    1. To Stop/Start/Restart/Status the service: `service solr start`
    1. The script and .tgz file can now be deleted
1. Configure Solr Cloud Production Installation
    1. All Solr configuration parameters are contained in /var/solr/solr.in.sh, edit this file and set:
        1. SOLR_HOST comment in and set to the machine's host name
        1. ZK_HOST comment in and set to the zookeeper hosts list with chroot (i.e. zk1-host,zk2-host,zk3-host/kla_collection)
        1. SOLR_OPTS AutoCommit comment in and set to appropriate an value in milliseconds (recommended: 300000)
        1. SOLR_OPTS AutoSoftCommit settings comment in and set to an appropriate value in milliseconds (recommended: 10000)
    1. Verify that Zookeeper has been started/is running (see above).
    1. Upload Solr configuration to Zookeeper
        1. `cd /opt/solr-5.3.1/server/scripts/cloud-scripts`
        1. ` ./zkcli.sh -cmd upconfig -zkhost [zk1-host]:2181,[zk2-host]:2181,[zk3-host]:2181/kla_chroot -confname kla_config -solrhome /opt/solr-5.3.1/server/solr -confdir /opt/solr-5.3.1/server/solr/configsets/data_driven_schema_configs/conf`
    1. Run following to verfiy config in ZK
        1. `./zkcli.sh -cmd list -zkhost [zk1-host]:2181,[zk2-host]:2181,[zk3-host]:2181/kla\_it | more`
    1. Restart Solr: `service solr restart`
        1. Confirm that Solr started: `/opt/solr-5.3.1/bin/solr status` or `service solr status`
        1. Solr can be stopped with the command: `service solr stop`
        1. Verify Solr up by going to the url: http://<solr-host>:8983/solr
    1.  Create the KAL Collection (OverSharded, Leader/Follower, with replication)
        1. From a browser submit the following URL: `http://<solr-host>:8983/solr/admin/collections?action=CREATE&name=kla_collection&numShards=20&replicationFactor=2&maxShardsPerNode=21&collection.configName=kla_config`

### -Option 2, Manual Installation (Linux)
1. Install Solr Cloud on Linux (requires Java, Zookeeper)
    1. `cd /opt`
    1. `wget http://apache.mirrors.pair.com/lucene/solr/5.3.1/solr-5.3.1.tgz`
    1. `tar xfz solr-5.3.1.tgz`
    1. Open the file /opt/solr-5.3.1/server/solr/configsets/data_driven_schema_configs/conf/solrconfig.xml
    1. Modify AutoCommit and AutoSoftCommit settings to appropriate value in milliseconds (i.e. 15000) and save the file.
    1. Verify that Zookeeper has been started/is running (see above).
1. Configure Solr Cloud Production Installation
    1. Upload Solr configuration to Zookeeper
        1. `cd /opt/solr-5.3.1/server/scripts/cloud-scripts`
        1. `./zkcli.sh -cmd upconfig -zkhost [zk1-host]:2181,[zk2-host]:2181,[zk3-host]:2181/kla_chroot -confname kla_config -solrhome /opt/solr-5.3.1/server/solr -confdir /opt/solr-5.3.1/server/solr/configsets/data_driven_schema_configs/conf`
    1. Run following to verfiy config in ZK
        1. `./zkcli.sh -cmd list -zkhost [zk1-host]:2181,[zk2-host]:2181,[zk3-host]:2181/kla_chroot | more`
    1.  Start Solr (repeat for all Solr Servers in Solr Cloud)
        1. `cd /opt/solr-5.3.1/`
        1. `bin/solr start -c -p 8983 -m 8G -s server/solr -d server -z [zk1-host]:2181,[zk2-host]:2181,[zk3-host]:2181/kla_chroot` note: this command specifies an 8 Gigabyte Java heap size, you may need to adjust the heap size (-m option) to a value appropriate to your hardware configuration.
        1. Confirm that Solr started: `bin/solr status`
        1. Solr can be stopped with the command: `bin/solr stop`
        1. Verify Solr up by going to the url: http://[ip where solr started]:8983/solr
    1.  Create the KLA Collection (OverSharded, Leader/Follower, with replication)
        1. From a browser submit the following URL: `http://<solr-host>:8983/solr/admin/collections?action=CREATE&name=kla_collection&numShards=20&replicationFactor=2&maxShardsPerNode=21&collection.configName=kla_config`

# Developer Notes

### Solr shortcuts:
1. To remove all data from the solr kla collection: `http://localhost:8983/solr/kla_collection/update?stream.body=<delete><query>*:*</query></delete>&commit=true`
1. To delete the Solr collection in Zookeeper:
    1. `/opt/solr/server/scripts/cloud-scripts/`
    1. `./zkcli.sh -cmd clear -z localhost:2181/kla_chroot /kla_chroot`


#### *~BETA~*
### Jena/Fuseki Local Persistence
#### *~BETA~*
The Knowtify Data Service requires a local data store to be configured so that local data can be stored, managed, and served up to clients. There are 2 possible configurations of the lcoal data store, both of which involve the jena TDB database.

1. Embedded (the database runs in-process to the Data Service). Use this in environments where you are certain there will only ever be a single instance of the Knowtify Data Service to server all of the users.
    1. The libraries are already included in the WAR. 
1. Shared (the database is managed as an external service under Fuseki, which is a RESTful API service that sits on top of Jena). Use this in environments where there is a chance that there could be more than one Knowtify Data Service running such that all KDS instances need to share a common set of Properties/Preferences. This should be the default case.
    1. Install Fuseki 2.3.0 (or latest, as soon as it is out)
        1. For Linux: `http://psg.mtu.edu/pub/apache/jena/binaries/apache-jena-fuseki-2.3.0.tar.gz`
        2. For Windows: `http://psg.mtu.edu/pub/apache/jena/binaries/apache-jena-fuseki-2.3.0.zip`
    1. Unpack the archive into an appropriate directory.
    1. Copy the config files (kla.ttl and shiro.ini) into the root of the where Fuseki was unpacked.
    1. Open kla.ttl and make sure that the directory specified for the location of the TDB database exists.
    1. Start the Fuseki server
        Linux: `./fuseki-server --loc=/temp/KnowtifyData/knowtify --port 3030 -v /kla`
        Windows: `fuseki-server.bat --loc=/temp/KnowtifyData/knowtify --port 3030 -v /kla`

### Maven Deployment to Tomcat:
Be sure to setup your local Tomcat correctly, you need to update

    1. TOMCAT-HOME/conf/tomcat-users.xml
    1. .m2/settings.xml
    1. for setup information see http://www.journaldev.com/4738/how-to-deploy-maven-war-project-in-tomcat-automatically

